---
title: "Computational Musicology 2020-2021"
author: "Jim Buissink"
#date: "2/9/2021"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(spotifyr)
library(tidyverse)
library(knitr)
library(ggthemes)
library(plotly)
library(compmus)
library(ggplot2)
library(grid)
library(gridExtra)
```

### Using Spotify’s **lower-level track audio features** to find differences in Kanye's albums

```{r, echo = FALSE}
YEE <- get_playlist_audio_features(
    "Jim Buissink",
    "2CcGtxKk4k5EbZC53tCBTr"
  ) %>%
  add_audio_analysis()

TCD <- get_playlist_audio_features(
    "Jim Buissink",
    "388Cb240QQLt1i5P9iVH6j"
  ) %>%
  #slice(2:13) %>%
  add_audio_analysis()

album123 <-
  YEE %>%
  mutate(album = "YEEZUS") %>%
  bind_rows(TCD %>% mutate(album = "The College Dropout"))
  
```

```{r, echo=FALSE}
# EOEs <- get_playlist_audio_features(
#     "Jim Buissink",
#     "3feALye5YioFPOoV6d7LrP"
#   ) %>%
#   slice(1:11) %>%
#   add_audio_analysis()
# 
# JIK <- get_playlist_audio_features(
#     "Jim Buissink",
#     "6LDcbbYnHVHlfPYUbRBY1H"
#   ) %>%
#   add_audio_analysis()

```

```{r, echo=FALSE}
plottt1 <- album123 %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(album, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = album)) +
  geom_boxplot(outlier.shape = NA)  + theme(legend.position = c(0.70, 0.8),
          legend.direction = "horizontal") +
  #scale_fill_viridis_d() +
  labs(x = "Timbre Coefficients", y = "", fill = "Album")
# 
# plottt12 <- album123 %>%
#   mutate(
#     timbre =
#       map(
#         segments,
#         compmus_summarise,
#         timbre,
#         method = "mean"
#       )
#   ) %>%
#   select(album, timbre) %>%
#   compmus_gather_timbre() %>%
#   ggplot(aes(x = basis, y = value, fill = album)) +
#   geom_violin() + theme(legend.position = "none") +
#   #scale_fill_viridis_d() +
#   labs(x = "Spotify Timbre Coefficients", y = "", fill = "Album")

```

```{r, echo=FALSE}
plottt2 <- album123 %>%
  mutate(
    pitches =
      map(
        segments,
        compmus_summarise,
        pitches,
        method = "rms", norm = "euclidean"
      )
  ) %>%
  select(album, pitches) %>%
  compmus_gather_chroma() %>%
  ggplot(aes(x = pitch_class, y = value, fill = album)) +
  geom_boxplot(outlier.shape = NA) + theme(legend.position = "none") +
  #scale_fill_viridis_d() +
  labs(x = "Pitch Classes", y = "", fill = "Album")
# 
# plottt22 <- album123 %>%
#   mutate(
#     pitches =
#       map(
#         segments,
#         compmus_summarise,
#         pitches,
#         method = "rms", norm = "euclidean"
#       )
#   ) %>%
#   select(album, pitches) %>%
#   compmus_gather_chroma() %>%
#   ggplot(aes(x = pitch_class, y = value, fill = album)) +
#   geom_violin()  +
#   labs(x = "Spotify Pitch Classes", y = "", fill = "Album")
```

```{r, echo=FALSE}
# 
# # Create two plots without legends
# plotttx <- album123 %>%
#   mutate(
#     pitches =
#       map(
#         segments,
#         compmus_summarise,
#         pitches,
#         method = "rms", norm = "euclidean"
#       )
#   ) %>%
#   select(album, pitches) %>%
#   compmus_gather_chroma() %>%
#   ggplot(aes(x = pitch_class, y = value, fill = album)) +
#   geom_boxplot(outlier.shape = NA) + 
#   #scale_fill_viridis_d() +
#   labs(x = "Spotify Pitch Classes", y = "", fill = "Album") +
#   theme(legend.position = "right", legend.box = "horizontal") 
# 
# # Create user-defined function, which extracts legends from ggplots
# extract_legend <- function(my_ggp) {
#   step1 <- ggplot_gtable(ggplot_build(my_ggp))
#   step2 <- which(sapply(step1$grobs, function(x) x$name) == "guide-box")
#   step3 <- step1$grobs[[step2]]
#   return(step3)
# }
# 
# # Apply user-defined function to extract legend
# shared_legend <- extract_legend(plotttx)

# Draw plots with shared legend 
grid.arrange(arrangeGrob(plottt1, plottt2, ncol = 1, top="Spotify’s lower-level track audio analysis"))
```

***

We already saw from the previous pages that we were able to distinguish Kanye's work using Spotify's audio features like valence, energy & tempo. These features are quite high-level, meaning that Spotify already did a lot of work to obtain these features. It is also possible to obtain lower level features from Spotify's API, which might also add extra information when trying to cluster albums into groups.

We are going to compare two albums, *Yeezus* & The *College Dropout (TCD)*. These albums are, according to analysis using the higher level features, the most contrasting works from Kanye's discography. For this comparison we will look at the **average timbre coefficients** and the **average pitch classes**. From the two distributions of these features, we can actually see that **these two albums are not as distinct as we might have thought**. 

For the **timbre coefficients** we see that they are **distributed similarly** for both albums. There is an exception for coefficient c05 where the mean is a bit higher for TCD compared to Yeezus, and there is one for coefficient c07 where the distribution for Yeezus is left-skewed, and vice versa. For the **pitch classes**, there is a bit **more distinction** between the two albums. **Especially the variance** of the pitch classes, which is significantly larger for Yeezus than for TDC, could potentially serve as an extra variable when trying to cluster Kanye's albums.

Further work should be done to confirm this for his other albums as well. 

### Comparing the structure of the opening tracks of My Beautiful Dark Twisted fantasy and Yeezus 

```{r, echo=FALSE}
dark_fantasy <-  get_tidy_audio_analysis("7yNK27ZTpHew0c55VvIJgm") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"              # Change summary & norm.
      )
  )


bind_rows(
  dark_fantasy%>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  dark_fantasy %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "")

```

***

Another way to compare Kanye's music is to look at the way he structured his songs using self-similarity matrices (SSMs). Lets have a look at the opening tracks of his 5th album My Beautiful Dark Twisted Fantasy (2010) and his 6th album Yeezus (2013). 

My Beautiful Dark Twisted Fantasy (MBDTF) features a maximalist aesthetic & clean production quality. The album is critically acclaimed and won a Grammy for best rap album, it is listed as the 14th best album on Metacritic with a score of 94. Wikipedia classified the album as Hip hop / prog-rap/ popart/ pop / rap opera. If we think about most of these genres, we think of a clearly structured song. The opening track for MBDTF is self titled 'Dark Fantasy' and checks this box. 

From both the chroma and the timbre matrix, we can see the structure of the song. After a short intro, we start with a prolonged version of the chorus. From the diagonal lines in the chroma matrix, we can clearly see that this chorus itself is repeating a couple of bars. Following this we have two verses from Kanye with a shorter version of the chorus in between. After the 3rd chorus, we have a small bridge section and another short version of the chorus. The track then ends with an instrumental loop and after a brief silence + sharp sound (clearly depicted in the timbre matrix), we encounter the long version of the chorus one last time.


### Comparing the structure of the opening tracks of My Beautiful Dark Twisted fantasy and Yeezus cont.

```{r, echo = FALSE}
on_sight <-  get_tidy_audio_analysis("1gqkRc9WtOpnGIqxf2Hvzr") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"              # Change summary & norm.
      )
  )

bind_rows(
  on_sight%>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  on_sight %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")

) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() + 
  labs(x = "", y = "")
```

***

Contrasting his previous release, Kanye's approach for Yeezus is in favor of a more minimalist approach. The album has been characterized as West's most experimental and sonically abrasive work. Because of the great reviews for his previous album, expectations were sky high for this release. But, instead of trying to one up his previous masterpiece he does a complete 180. Yeezus is a divisive album, and clearly does not fit in the 'Old Kanye' box. Lets have a look at the opening track 'On Sight'. 

It is very hard to see a clear structure from the matrices, and every line is very blurry. This could be because of the way the track is produced, very compressed and industrial sounding. In the chroma matrix we do see the interlude clearly, starting at around 75 seconds into the song, but is less visible in the timbre matrix. Vice versa, the outro which starts at around 120 seconds into the song is visible in the timbre matrix, but not in the chroma matrix.


### Introduction

> I miss the old Kanye... 
> - Kanye West (2016)

But who, what & when is this 'old' Kanye? Is it possible to uncover who the old Kanye is by analyzing his music? Are there any significant differences in his earlier and later works, and is there a way to cluster these works so we have an 'old' Kanye and a 'new' Kanye? 

To find an answer to these questions, we will build a corpus consisting of the 9 studio albums released by Kanye West and his 2 collaborative albums. Any non-musical tracks, e.g. skits, featured on the albums will be included. If a distinction can be made between old Kanye and new Kanye, we expect there to be musical differences between his first three albums and his latter releases. This is where the music changed from cheery & soulful to dark & electronic-inspired, so we expect to see differences in valence. His latest album, Jesus Is King (2019), is an outlier concerning this stylistic change and could mean that Kanye West is returning to his original sound, or that potentially a 'future' Kanye is in the making.

The 2 collaborative albums (with Jay-Z and Kid Cudi, respectivly) are included as I feel that Kanye did have enough of an influence during the creation of these works so his personality should be reflected in the music, although it might be for only 50%. Singles and tracks where Kanye was a featured artist are excluded from the corpus, but might serve as a reference in a later stages.

### Distribution of Valence 
```{r, echo=FALSE}
kanye_albums <- get_playlist_audio_features("", "4bQNKK5gntETwqlI1RW9w1")


#ADD MEAN FEATURES
kanye_albums  <- transform(kanye_albums,
    mean_tempo = mean(tempo),
    mean_valence = mean(valence),
    mean_speechiness = mean(speechiness),
    mean_energy = mean(energy)

)


#ADD POSITIVE COLUMN
kanye_albums <- kanye_albums %>% add_column(mood = 'yes')
kanye_albums <- kanye_albums %>% 
  mutate(mood= ifelse(track.album.name == 'The College Dropout' | track.album.name == 'Graduation' | track.album.name == 'Late Registration', "Positive", "Negative"))

#ADD AVG Tempo Column
kanye_albums <- kanye_albums %>% 
  mutate(avg_tempo= ifelse(track.album.name == 'The College Dropout' | track.album.name == 'JESUS IS KING' | track.album.name == 'Graduation' | track.album.name == 'Late Registration', "< 100 bpm", "> 100 bpm"))


```

```{r, echo=FALSE}

#BOXPLOTS 1
p <- ggplot(kanye_albums, aes(x = reorder(track.album.release_date, desc(track.album.release_date)), y = valence, fill=mood)) + 
  geom_boxplot() 
p <- p + scale_x_discrete(labels=c("JESUS IS KING","KIDS SEE GHOSTS","ye","The Life Of Pablo", "Yeezus", "Watch The Throne", "My Beautiful Dark Twisted Fantasy", "808s & Heartbreak", "Graduation", "Late Registration", "The College Dropout"))
p <- p +  geom_hline(yintercept = 0.40, linetype = 3)
p <- p + coord_flip() + labs(title="Distribution of the valence feature",y="", x = "")

p <- p + annotate(
  "text",
  x = 2.5, y = 0.58,
  label = "Average\nvalence",
  vjust = 1, size = 3, color = "grey40"
)

p <- p + annotate(
  "curve",
  x = 2.5, y = 0.58,
  xend = 2.5, yend = 0.40,
  arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
  color = "grey40")
p <- p + theme(legend.title=element_blank())
p #+ theme_economist_white()
```

***

Before we can cluster the works in to two (or potentially three) groups, we need to find out which audio features contain the most useful information.

As already was mentioned in the previous section, valence seems to be a good indicator. Below is a plot of the distribution of the valence for each album. We can see that his first three albums sound positive (valence > 0.5) and the latter sound negative (valence < 0.5)

### Distribution of Tempo 
```{r, echo=FALSE}
#BOXPLOTS 2
p2 <- ggplot(kanye_albums, aes(x = reorder(track.album.release_date, desc(track.album.release_date)), y = tempo, fill=avg_tempo)) + 
  geom_boxplot() 
p2 <- p2 + scale_x_discrete(labels=c("JESUS IS KING","KIDS SEE GHOSTS","ye","The Life Of Pablo", "Yeezus", "Watch The Throne", "My Beautiful Dark Twisted Fantasy", "808s & Heartbreak", "Graduation", "Late Registration", "The College Dropout"))
p2 <- p2 +  geom_hline(yintercept = 112, linetype = 3)
p2 <- p2 +  coord_flip() + labs(title="Distribution of the tempo feature",y="", x = "")

p2 <- p2 + annotate(
  "text",
  x = 10, y = 135,
  label = "Average\ntempo",
  vjust = 1, size = 3, color = "grey40"
)

p2 <- p2 + annotate(
  "curve",
  x = 10, y = 135,
  xend = 9, yend = 112,
  arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
  color = "grey40")

p2 <- p2 + theme(legend.title=element_blank())
p2

```

***

Another feature with similar behavior is the tempo. The BPM used for hip-hop beats is generally around 60-100 bpm. We can see from the plot blow that only his first three albums have a tempo < 100, with the an exception for his latest album 'JESUS IS KING'.


### Emotion

```{r , echo=FALSE}
mood <- kanye_albums %>% ggplot(aes(x = valence, y = energy, color = track.album.release_date)) +
  geom_jitter(alpha = 0.6) + geom_hline(yintercept = 0.5) + geom_vline(xintercept = 0.5) 

mood <- mood + labs(title="Distribution of tracks according to valence and energy", colour = "Release date")

mood <- mood + annotate(
  "text",
  x = 0.90, y = 0.95,
  label = "HAPPY",
  vjust = 1, size = 4
)

mood <- mood + annotate(
  "text",
  x = 0.1, y = 0.95,
  label = "ANGRY",
  vjust = 1, size = 4
)

mood <- mood + annotate(
  "text",
  x = 0.1, y = 0.1,
  label = "SAD",
  vjust = 1, size = 4
)

mood <- mood + annotate(
  "text",
  x = 0.90, y = 0.1,
  label = "CALM",
  vjust = 1, size = 4
)
fig <- ggplotly(mood)

fig
```

***

Whereas valence as a standalone feature tells us something about the general mood of a song, e.g. positive or negative, we could combine the valence with the energy feature. This pair of parameters now tells us something about the emotional level of a track. Low energy + low valence songs are considered 'sad', low valence + high energy are 'angry', songs with high valence + low energy are 'calm' and high valence + high energy are 'happy'. This section needs some more work.

### Chromagram

```{r, echo=FALSE}
angriest <-
  get_tidy_audio_analysis("46fk9wjYcPm0sgym2b7EEE") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
```

```{r, echo=FALSE}
#`manhattan`, `euclidean`, or `chebyshev`
angriest %>%
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

*** 

Let's have a look at the most angriest track in Kanye's discography: "We Major" from the album "Late Regristration". This album itself is the second most happiest album (looking at mean Valence + mean Energy) which makes this track a significant outlier. Upon listening to the the track, I don't get a particular angry vibe from it. Let's find out what is happening in the track by expecting its chromagram.

From the chromagram, we can see a lot of movement in the track but a clear break happening at the 300 seconds mark. During this break/bridge, we can see that everything is F#/G flat. At this part, the music doesn't really change that much but we have Kanye West speak in an aggressive tone, clearly different from the rest